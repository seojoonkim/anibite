#!/usr/bin/env python3
"""
ë‚˜ë¬´ìœ„í‚¤ ìºë¦­í„° í•œêµ­ì–´ ì´ë¦„ í¬ë¡¤ëŸ¬ v7
ì—„ê²©í•œ ë§¤ì¹­: ì¸í¬ë°•ìŠ¤ì—ì„œ ì¼ë³¸ì–´+ì˜ì–´ ì´ë¦„ì´ ë‘˜ ë‹¤ ì¼ì¹˜í•´ì•¼ í•¨
5ê°œ ë³‘ë ¬ Worker, 10ê°œë§ˆë‹¤ ì§„í–‰ìƒí™©
"""
import sys
import os
import re
import asyncio
from urllib.parse import quote, unquote
from datetime import datetime

sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
sys.path.insert(0, os.path.join(os.path.dirname(os.path.dirname(os.path.abspath(__file__))), 'backend'))

from database import db

try:
    from playwright.async_api import async_playwright
except ImportError:
    print("Error: playwright not installed")
    sys.exit(1)


# Configuration
MAX_WORKERS = 5
MAX_CHARACTERS = 50  # None = ì „ì²´, í…ŒìŠ¤íŠ¸ìš©
REQUEST_DELAY = 0.5


# Global counters
processed_count = 0
success_count = 0
lock = asyncio.Lock()


def log(msg):
    print(msg, flush=True)


def get_characters_to_crawl(limit=None):
    query = """
        SELECT DISTINCT
            c.id,
            c.name_full,
            c.name_native,
            c.favourites
        FROM character c
        WHERE c.name_korean IS NULL
          AND c.name_native IS NOT NULL
          AND c.name_full NOT IN ('Narrator', 'Unknown', 'Extra')
          AND c.name_native != ''
          AND LENGTH(c.name_native) >= 2
        ORDER BY c.favourites DESC
    """
    if limit:
        query += f" LIMIT {limit}"
    return db.execute_query(query)


def extract_kanji(text):
    """í•œìë§Œ ì¶”ì¶œ"""
    return re.sub(r'[^\u4e00-\u9fff]', '', text)


def is_valid_korean_name(text):
    if not text:
        return False
    text = text.strip()
    if not re.match(r'^[ê°€-í£]+(\s[ê°€-í£]+)?$', text):
        return False
    clean = text.replace(' ', '')
    if len(clean) < 2 or len(clean) > 10:
        return False
    blacklist = ['ëª©ì°¨', 'ê°œìš”', 'ë“±ì¥ì¸ë¬¼', 'ì£¼ì¸ê³µ', 'ì„¤ëª…', 'íŠ¹ì§•', 'ë¶„ë¥˜',
                 'í¸ì§‘', 'í† ë¡ ', 'ì—­ì‚¬', 'ìµœê·¼', 'ìˆ˜ì •', 'ì‹œê°', 'ê¸°ëŠ¥',
                 'ì‘í’ˆ', 'ì‹œë¦¬ì¦ˆ', 'ì• ë‹ˆ', 'ë§Œí™”', 'ê²Œì„', 'ì†Œì„¤', 'ë”ë³´ê¸°',
                 'ì„±ìš°', 'ë°°ìš°', 'ì¶œìƒ', 'ì¶œì‹ ', 'ê¸°íƒ€', 'ê´€ê³„', 'ê°ì£¼', 'ëª©ë¡']
    if text in blacklist or any(b in text for b in blacklist):
        return False
    return True


def is_character_document(page_text):
    """ìºë¦­í„° ë¬¸ì„œì¸ì§€ í™•ì¸"""
    header = page_text[:4000]

    # ë¶„ë¥˜ í™•ì¸
    category_line = ""
    for line in header.split('\n')[:15]:
        if 'ë¶„ë¥˜' in line:
            category_line = line
            break

    # ì‹¤ì¡´ ì¸ë¬¼ ì¹´í…Œê³ ë¦¬ ì œì™¸
    real_person_cats = ['ë‚¨ë°°ìš°', 'ì—¬ë°°ìš°', 'ê°€ìˆ˜', 'ì•„ì´ëŒ',
                        'ì¶œìƒ', 'ë°ë·”', 'ì¶œì‹  ì¸ë¬¼', 'ì†Œì† ì—°ì˜ˆì¸']
    for cat in real_person_cats:
        if cat in category_line:
            return False

    # ì§ì—…ì´ ë°°ìš°ì¸ ê²½ìš° ì œì™¸ (ìºë¦­í„° ì„¤ì •ìƒ ë°°ìš°ëŠ” OK)
    lines = header.split('\n')
    for i, line in enumerate(lines):
        if line.strip() == 'ì§ì—…':
            if i + 1 < len(lines):
                next_line = lines[i + 1]
                # "ë°°ìš°(xxxxë…„~)" ê°™ì€ íŒ¨í„´ì€ ì‹¤ì¡´ ì¸ë¬¼
                if re.search(r'ë°°ìš°\s*\(\d{4}', next_line):
                    return False

    # ì„±ìš° ì •ë³´ í•„ìˆ˜
    if 'ì„±ìš°' not in header:
        return False

    return True


def match_infobox_name(page_text, target_native, target_english):
    """
    ì¸í¬ë°•ìŠ¤ì—ì„œ ì¼ë³¸ì–´+ì˜ì–´ ì´ë¦„ ì—„ê²© ë§¤ì¹­

    ì¡°ê±´:
    1. í•œìê°€ ì •í™•íˆ ì¼ì¹˜í•´ì•¼ í•¨ (í•„ìˆ˜)
    2. ì˜ì–´ ì´ë¦„ì´ ì¼ì¹˜í•˜ë©´ ì¶”ê°€ ê²€ì¦ (ì„ íƒ)
    """
    target_kanji = extract_kanji(target_native)

    # í•œìê°€ 2ì ë¯¸ë§Œì´ë©´ ì›ë³¸ ê·¸ëŒ€ë¡œ ì‚¬ìš©
    if len(target_kanji) < 2:
        target_kanji = target_native

    # ì˜ì–´ ì´ë¦„ (ì „ì²´)
    english_full = target_english.lower().replace(' ', '')

    # ìƒë‹¨ 80ì¤„ì—ì„œ ì¸í¬ë°•ìŠ¤ ì°¾ê¸°
    lines = page_text.split('\n')[:80]

    for line in lines:
        # ì¼ë³¸ì–´|ì˜ì–´ ë˜ëŠ” ì¼ë³¸ì–´/ì˜ì–´ íŒ¨í„´
        if ('/' in line or 'ï½œ' in line or '|' in line) and re.search(r'[A-Za-z]', line):
            line_kanji = extract_kanji(line)

            # í•œì ì •í™• ì¼ì¹˜ (í•„ìˆ˜!)
            if not line_kanji or target_kanji != line_kanji:
                continue

            # í•œìê°€ ì •í™•íˆ ì¼ì¹˜í•˜ë©´, ì˜ì–´ë„ í™•ì¸
            line_english = ''.join(re.findall(r'[A-Za-z]+', line)).lower()

            # ì˜ì–´ê°€ ì¶©ë¶„íˆ ì¼ì¹˜í•˜ë©´ í™•ì‹¤í•œ ë§¤ì¹­
            if english_full and line_english:
                # ì˜ì–´ ì´ë¦„ì´ 70% ì´ìƒ ì¼ì¹˜í•˜ë©´ OK
                common = sum(1 for c in english_full if c in line_english)
                if common >= len(english_full) * 0.7:
                    return True

            # í•œìë§Œ ì •í™•íˆ ì¼ì¹˜í•´ë„ OK (ì˜ì–´ê°€ ì—†ëŠ” ê²½ìš°)
            return True

    return False


def extract_korean_title(page_text):
    """í˜ì´ì§€ ìƒë‹¨ì—ì„œ í•œê¸€ ì œëª© ì¶”ì¶œ"""
    lines = page_text.split('\n')
    for line in lines[:20]:
        line = line.strip()
        if is_valid_korean_name(line):
            return line
    return None


async def search_and_find(page, search_term, name_native, name_full):
    """ê²€ìƒ‰ í›„ ìºë¦­í„° ì°¾ê¸°"""
    search_url = f"https://namu.wiki/Search?q={quote(search_term)}"

    try:
        await page.goto(search_url, timeout=15000)
        await page.wait_for_load_state('domcontentloaded')
        await asyncio.sleep(0.5)

        # ê²€ìƒ‰ ê²°ê³¼ì—ì„œ URL ì¶”ì¶œ
        results = await page.evaluate("""
            () => {
                const items = [];
                const seen = new Set();
                document.querySelectorAll('a[href^="/w/"]').forEach(a => {
                    const href = a.getAttribute('href');
                    if (href.includes('#') || href.includes(':')) return;
                    if (seen.has(href)) return;
                    seen.add(href);
                    items.push(href);
                });
                return items.slice(0, 30);
            }
        """)

        # í•œê¸€ ì´ë¦„ URLë§Œ
        korean_candidates = []
        for href in results:
            try:
                decoded = unquote(href.replace('/w/', ''))
                name_part = re.sub(r'\([^)]*\)$', '', decoded).strip()
                if is_valid_korean_name(name_part):
                    korean_candidates.append({'name': name_part, 'href': href})
            except:
                pass

        # ì¤‘ë³µ ì œê±°
        seen = set()
        unique = []
        for c in korean_candidates:
            if c['name'] not in seen:
                seen.add(c['name'])
                unique.append(c)

        # ê° í›„ë³´ í™•ì¸
        for candidate in unique[:8]:
            korean_name = candidate['name']
            href = candidate['href']

            try:
                doc_url = f"https://namu.wiki{href}"
                await page.goto(doc_url, timeout=10000)
                await page.wait_for_load_state('domcontentloaded')
                await asyncio.sleep(0.3)

                page_text = await page.evaluate("document.body.innerText")

                if "í•´ë‹¹ ë¬¸ì„œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤" in page_text:
                    continue

                # 1. ìºë¦­í„° ë¬¸ì„œì¸ì§€
                if not is_character_document(page_text):
                    continue

                # 2. ì¸í¬ë°•ìŠ¤ì—ì„œ ì¼ë³¸ì–´+ì˜ì–´ ë§¤ì¹­
                if match_infobox_name(page_text, name_native, name_full):
                    title = extract_korean_title(page_text)
                    if title:
                        return title
                    return korean_name

            except:
                pass

            await asyncio.sleep(REQUEST_DELAY)

    except:
        pass

    return None


async def find_korean_name(page, name_native, name_full):
    """ë‚˜ë¬´ìœ„í‚¤ì—ì„œ í•œêµ­ì–´ ì´ë¦„ ì°¾ê¸° (ë‹¤ì¤‘ ê²€ìƒ‰)"""

    # 1. ì¼ë³¸ì–´ ì´ë¦„ìœ¼ë¡œ ê²€ìƒ‰
    result = await search_and_find(page, name_native, name_native, name_full)
    if result:
        return result

    # 2. ì˜ì–´ ì´ë¦„ìœ¼ë¡œ ê²€ìƒ‰
    result = await search_and_find(page, name_full, name_native, name_full)
    if result:
        return result

    # 3. ì˜ì–´ ì´ë¦„ ì¼ë¶€ë¡œ ê²€ìƒ‰ (ì„±ë§Œ, ì´ë¦„ë§Œ)
    parts = name_full.split()
    if len(parts) >= 2:
        # ì„±ìœ¼ë¡œ ê²€ìƒ‰
        result = await search_and_find(page, parts[-1], name_native, name_full)
        if result:
            return result

    return None


async def worker(worker_id, queue, context, total_count):
    global processed_count, success_count

    page = await context.new_page()

    try:
        while True:
            try:
                character = queue.get_nowait()
            except asyncio.QueueEmpty:
                break

            char_id = character['id']
            name_full = character['name_full']
            name_native = character['name_native']

            korean_name = None

            try:
                korean_name = await find_korean_name(page, name_native, name_full)

                if korean_name:
                    db.execute_update(
                        "UPDATE character SET name_korean = ? WHERE id = ?",
                        (korean_name, char_id)
                    )
            except:
                pass

            async with lock:
                processed_count += 1
                current = processed_count

                if korean_name:
                    success_count += 1
                    log(f"âœ“ [{current}/{total_count}] {name_full} ({name_native}) â†’ {korean_name}")
                else:
                    log(f"âœ— [{current}/{total_count}] {name_full}")

                if current % 10 == 0:
                    rate = success_count / current * 100 if current > 0 else 0
                    log(f"\n{'='*60}")
                    log(f"ğŸ“Š ì§„í–‰ìƒí™©: {current}/{total_count} ({current/total_count*100:.1f}%)")
                    log(f"   ì„±ê³µ: {success_count}ê°œ ({rate:.1f}%)")
                    log(f"   ì‹¤íŒ¨: {current - success_count}ê°œ")
                    log(f"{'='*60}\n")

    finally:
        await page.close()


async def main():
    global processed_count, success_count

    log("=" * 60)
    log("ğŸš€ ë‚˜ë¬´ìœ„í‚¤ ìºë¦­í„° í•œêµ­ì–´ ì´ë¦„ í¬ë¡¤ëŸ¬ v7")
    log(f"   ì—„ê²©í•œ ë§¤ì¹­ + {MAX_WORKERS}ê°œ ë³‘ë ¬ Worker")
    log("=" * 60)

    log("\nğŸ“‹ ì²˜ë¦¬í•  ìºë¦­í„° ì¡°íšŒ ì¤‘...")
    characters = get_characters_to_crawl(limit=MAX_CHARACTERS)
    total_count = len(characters)

    log(f"   ì´ {total_count}ê°œ ìºë¦­í„° ë°œê²¬")

    if total_count == 0:
        log("âœ… ì²˜ë¦¬í•  ìºë¦­í„°ê°€ ì—†ìŠµë‹ˆë‹¤!")
        return

    processed_count = 0
    success_count = 0

    queue = asyncio.Queue()
    for char in characters:
        await queue.put(char)

    log(f"\nğŸ”„ í¬ë¡¤ë§ ì‹œì‘ ({MAX_WORKERS}ê°œ Worker)...")
    start_time = datetime.now()

    async with async_playwright() as p:
        browser = await p.chromium.launch(headless=True)
        context = await browser.new_context(
            user_agent='Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36'
        )

        workers = [
            worker(i, queue, context, total_count)
            for i in range(MAX_WORKERS)
        ]

        await asyncio.gather(*workers)

        await context.close()
        await browser.close()

    elapsed = (datetime.now() - start_time).total_seconds()

    log(f"\n\n{'='*60}")
    log("ğŸ‰ í¬ë¡¤ë§ ì™„ë£Œ!")
    log(f"{'='*60}")
    log(f"  ì´ ì²˜ë¦¬: {processed_count}ê°œ")
    if processed_count > 0:
        log(f"  ì„±ê³µ: {success_count}ê°œ ({success_count/processed_count*100:.1f}%)")
        log(f"  ì‹¤íŒ¨: {processed_count - success_count}ê°œ")
    log(f"  ì†Œìš” ì‹œê°„: {elapsed/60:.1f}ë¶„")
    log(f"{'='*60}\n")


if __name__ == "__main__":
    asyncio.run(main())
