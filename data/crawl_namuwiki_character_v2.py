#!/usr/bin/env python3
"""
ë‚˜ë¬´ìœ„í‚¤ ìºë¦­í„° í•œêµ­ì–´ ì´ë¦„ ë³‘ë ¬ í¬ë¡¤ëŸ¬ v2
Playwright ì‚¬ìš© (CSR ëŒ€ì‘)
5ê°œ ë³‘ë ¬ ì²˜ë¦¬, 10ê°œë§ˆë‹¤ ì§„í–‰ìƒí™© ì•Œë¦¼
"""
import sys
import os
import re
import asyncio
from urllib.parse import quote
from datetime import datetime

sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
sys.path.insert(0, os.path.join(os.path.dirname(os.path.dirname(os.path.abspath(__file__))), 'backend'))

from database import db

try:
    from playwright.async_api import async_playwright
except ImportError:
    print("Error: playwright not installed")
    print("Run: pip install playwright && playwright install chromium")
    sys.exit(1)


# Configuration
MAX_WORKERS = 5  # 5ê°œ ë³‘ë ¬
MAX_CHARACTERS = None  # None = ì „ì²´
REQUEST_DELAY = 1.0  # ìš”ì²­ ê°„ê²©


# Global counters
processed_count = 0
success_count = 0
lock = asyncio.Lock()


def log(msg):
    """Immediate flush logging"""
    print(msg, flush=True)


def get_characters_to_crawl(limit=None):
    """í•œêµ­ì–´ ì´ë¦„ì´ í•„ìš”í•œ ìºë¦­í„° ì¡°íšŒ"""
    query = """
        SELECT DISTINCT
            c.id,
            c.name_full,
            c.name_native,
            c.favourites
        FROM character c
        WHERE c.name_korean IS NULL
          AND c.name_native IS NOT NULL
          AND c.name_full NOT IN ('Narrator', 'Unknown', 'Extra')
          AND c.name_native != ''
        ORDER BY c.favourites DESC
    """
    if limit:
        query += f" LIMIT {limit}"

    return db.execute_query(query)


def build_search_urls(name_native, name_full):
    """ê²€ìƒ‰í•  URL ëª©ë¡ ìƒì„±"""
    urls = []

    # 1. ì¼ë³¸ì–´ ì´ë¦„ìœ¼ë¡œ ê²€ìƒ‰ (ìµœìš°ì„ )
    if name_native:
        urls.append(f"https://namu.wiki/w/{quote(name_native)}")

    # 2. ì˜ì–´ ì´ë¦„ (Last First í˜•ì‹ ì‹œë„)
    if name_full:
        parts = name_full.split()
        if len(parts) >= 2:
            # "Lelouch Lamperouge" -> "Lamperouge Lelouch" ì‹œë„í•˜ì§€ ì•ŠìŒ
            # ëŒ€ì‹  ê·¸ëŒ€ë¡œ ì‹œë„
            urls.append(f"https://namu.wiki/w/{quote(name_full)}")

    return urls


def extract_korean_name_from_text(text, name_native, name_full):
    """í˜ì´ì§€ í…ìŠ¤íŠ¸ì—ì„œ í•œêµ­ì–´ ì´ë¦„ ì¶”ì¶œ"""
    lines = text.split('\n')

    # ê²€ìƒ‰ íŒ¨í„´ë“¤
    for i, line in enumerate(lines):
        line = line.strip()
        if not line:
            continue

        # íŒ¨í„´ 1: í•œê¸€ì´ë¦„ë§Œ ìˆëŠ” ì¤„ (ìºë¦­í„° ì´ë¦„ íŠ¹ì§•: 2-6ê¸€ì, ê³µë°± í¬í•¨ ê°€ëŠ¥)
        # ë³´í†µ ë¬¸ì„œ ìƒë‹¨ì— í•œê¸€ ì´ë¦„ì´ ë¨¼ì € ë‚˜ì˜´
        if re.match(r'^[ê°€-í£]+(\s[ê°€-í£]+)?$', line) and 2 <= len(line.replace(' ', '')) <= 10:
            # ë‹¤ìŒ ì¤„ì— ì¼ë³¸ì–´ë‚˜ ì˜ì–´ ì´ë¦„ì´ ìˆëŠ”ì§€ í™•ì¸
            if i + 1 < len(lines):
                next_line = lines[i + 1].strip()
                # ì¼ë³¸ì–´ ì´ë¦„ì´ í¬í•¨ë˜ì–´ ìˆìœ¼ë©´ ì´ í•œê¸€ì´ë¦„ì´ ë§ìŒ
                if name_native and name_native in next_line:
                    return line
                # ì˜ì–´ ì´ë¦„ì´ í¬í•¨ë˜ì–´ ìˆìœ¼ë©´
                if name_full and name_full.lower() in next_line.lower():
                    return line

        # íŒ¨í„´ 2: "í•œê¸€ì´ë¦„ (ì¼ë³¸ì–´, English)" í˜•ì‹
        match = re.match(r'^([ê°€-í£]+(?:\s[ê°€-í£]+)?)\s*[\(ï¼ˆ]', line)
        if match:
            korean = match.group(1).strip()
            if len(korean) >= 2 and len(korean) <= 10:
                # ê´„í˜¸ ì•ˆì— ì¼ë³¸ì–´ë‚˜ ì˜ì–´ê°€ ìˆëŠ”ì§€ í™•ì¸
                if name_native and name_native in line:
                    return korean
                if name_full and name_full.lower() in line.lower():
                    return korean

        # íŒ¨í„´ 3: í…Œì´ë¸”ì—ì„œ "ì´ë¦„" ë ˆì´ë¸” ë‹¤ìŒì— ë‚˜ì˜¤ëŠ” í•œê¸€
        if 'ì´ë¦„' in line or 'ë³¸ëª…' in line or 'ì„±ëª…' in line:
            # ê°™ì€ ì¤„ì´ë‚˜ ë‹¤ìŒ ì¤„ì—ì„œ í•œê¸€ ì´ë¦„ ì°¾ê¸°
            korean_matches = re.findall(r'[ê°€-í£]{2,6}(?:\s[ê°€-í£]{1,4})?', line)
            for km in korean_matches:
                if km not in ['ì´ë¦„', 'ë³¸ëª…', 'ì„±ëª…', 'ë“±ì¥ì¸ë¬¼', 'ì£¼ì¸ê³µ', 'ìºë¦­í„°']:
                    return km

            if i + 1 < len(lines):
                next_line = lines[i + 1].strip()
                korean_matches = re.findall(r'[ê°€-í£]{2,6}(?:\s[ê°€-í£]{1,4})?', next_line)
                for km in korean_matches:
                    if km not in ['ì´ë¦„', 'ë³¸ëª…', 'ì„±ëª…', 'ë“±ì¥ì¸ë¬¼', 'ì£¼ì¸ê³µ', 'ìºë¦­í„°']:
                        return km

    # íŒ¨í„´ 4: ì²« ë²ˆì§¸ í•œê¸€ ì´ë¦„ (ë¬¸ì„œ ì œëª©ì´ í•œê¸€ì¸ ê²½ìš°)
    first_korean = re.search(r'^([ê°€-í£]{2,6}(?:\s[ê°€-í£]{1,4})?)', text)
    if first_korean:
        name = first_korean.group(1)
        blacklist = ['ëª©ì°¨', 'ê°œìš”', 'ë“±ì¥ì¸ë¬¼', 'ì£¼ì¸ê³µ', 'ìºë¦­í„°', 'ì„¤ëª…', 'íŠ¹ì§•']
        if name not in blacklist:
            return name

    return None


async def crawl_single_character(context, character, total_count, semaphore):
    """ë‹¨ì¼ ìºë¦­í„° í¬ë¡¤ë§"""
    global processed_count, success_count

    char_id = character['id']
    name_full = character['name_full']
    name_native = character['name_native']

    korean_name = None

    async with semaphore:
        page = await context.new_page()

        try:
            urls = build_search_urls(name_native, name_full)

            for url in urls:
                try:
                    await page.goto(url, timeout=15000)
                    await page.wait_for_load_state('domcontentloaded')
                    await asyncio.sleep(0.3)

                    # í˜ì´ì§€ í…ìŠ¤íŠ¸ ì¶”ì¶œ
                    text = await page.evaluate("document.body.innerText")

                    # í˜ì´ì§€ê°€ ì—†ëŠ” ê²½ìš°
                    if "í•´ë‹¹ ë¬¸ì„œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤" in text:
                        continue

                    # í•œê¸€ ì´ë¦„ ì¶”ì¶œ
                    korean_name = extract_korean_name_from_text(text, name_native, name_full)

                    if korean_name:
                        # DB ì—…ë°ì´íŠ¸
                        db.execute_update(
                            "UPDATE character SET name_korean = ? WHERE id = ?",
                            (korean_name, char_id)
                        )
                        break

                except Exception as e:
                    pass

                await asyncio.sleep(REQUEST_DELAY)

        finally:
            await page.close()

    # ì¹´ìš´í„° ì—…ë°ì´íŠ¸ (thread-safe)
    async with lock:
        processed_count += 1
        current = processed_count

        if korean_name:
            success_count += 1
            log(f"âœ“ [{current}/{total_count}] {name_full} â†’ {korean_name}")
        else:
            log(f"âœ— [{current}/{total_count}] {name_full}")

        # 10ê°œë§ˆë‹¤ ì§„í–‰ìƒí™©
        if current % 10 == 0:
            rate = success_count / current * 100 if current > 0 else 0
            log(f"\n{'='*60}")
            log(f"ğŸ“Š ì§„í–‰ìƒí™©: {current}/{total_count} ({current/total_count*100:.1f}%)")
            log(f"   ì„±ê³µ: {success_count}ê°œ ({rate:.1f}%)")
            log(f"   ì‹¤íŒ¨: {current - success_count}ê°œ")
            log(f"{'='*60}\n")

    return korean_name


async def main():
    global processed_count, success_count

    log("=" * 60)
    log("ğŸš€ ë‚˜ë¬´ìœ„í‚¤ ìºë¦­í„° í•œêµ­ì–´ ì´ë¦„ í¬ë¡¤ëŸ¬ v2")
    log(f"   Playwright ì‚¬ìš©, {MAX_WORKERS}ê°œ ë³‘ë ¬ ì²˜ë¦¬")
    log("=" * 60)

    # ìºë¦­í„° ì¡°íšŒ
    log("\nğŸ“‹ ì²˜ë¦¬í•  ìºë¦­í„° ì¡°íšŒ ì¤‘...")
    characters = get_characters_to_crawl(limit=MAX_CHARACTERS)
    total_count = len(characters)

    log(f"   ì´ {total_count}ê°œ ìºë¦­í„° ë°œê²¬")

    if total_count == 0:
        log("âœ… ì²˜ë¦¬í•  ìºë¦­í„°ê°€ ì—†ìŠµë‹ˆë‹¤!")
        return

    # ì¹´ìš´í„° ì´ˆê¸°í™”
    processed_count = 0
    success_count = 0

    log(f"\nğŸ”„ í¬ë¡¤ë§ ì‹œì‘...")
    start_time = datetime.now()

    async with async_playwright() as p:
        browser = await p.chromium.launch(headless=True)
        context = await browser.new_context(
            user_agent='Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36'
        )

        # ì„¸ë§ˆí¬ì–´ë¡œ ë™ì‹œ ì‹¤í–‰ ì œí•œ
        semaphore = asyncio.Semaphore(MAX_WORKERS)

        # ëª¨ë“  ì‘ì—… ìƒì„±
        tasks = [
            crawl_single_character(context, char, total_count, semaphore)
            for char in characters
        ]

        # ë³‘ë ¬ ì‹¤í–‰
        await asyncio.gather(*tasks)

        await context.close()
        await browser.close()

    # ìµœì¢… ê²°ê³¼
    elapsed = (datetime.now() - start_time).total_seconds()

    log(f"\n\n{'='*60}")
    log("ğŸ‰ í¬ë¡¤ë§ ì™„ë£Œ!")
    log(f"{'='*60}")
    log(f"  ì´ ì²˜ë¦¬: {processed_count}ê°œ")
    log(f"  ì„±ê³µ: {success_count}ê°œ ({success_count/processed_count*100:.1f}%)")
    log(f"  ì‹¤íŒ¨: {processed_count - success_count}ê°œ")
    log(f"  ì†Œìš” ì‹œê°„: {elapsed/60:.1f}ë¶„")
    log(f"{'='*60}\n")


if __name__ == "__main__":
    asyncio.run(main())
