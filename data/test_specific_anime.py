"""
íŠ¹ì • ì• ë‹ˆë©”ì´ì…˜ 1ê°œ í¬ë¡¤ë§ í…ŒìŠ¤íŠ¸
"""
from crawler import AnimeCrawler
from anilist_client import AniListClient

def test_specific_anime():
    # ìƒˆë¡œ ë°œê²¬í•œ ì• ë‹ˆë©”ì´ì…˜ ID
    target_id = 187264

    print(f"ğŸ§ª ì• ë‹ˆë©”ì´ì…˜ ID {target_id} í¬ë¡¤ë§ í…ŒìŠ¤íŠ¸\n")

    client = AniListClient()
    crawler = AnimeCrawler()
    crawler.connect()

    cursor = crawler.conn.cursor()
    cursor.execute("SELECT COUNT(*) FROM anime")
    before_count = cursor.fetchone()[0]
    print(f"ğŸ“Š í˜„ì¬ ì• ë‹ˆë©”ì´ì…˜ ìˆ˜: {before_count}ê°œ\n")

    # íŠ¹ì • IDë¡œ ê²€ìƒ‰
    print(f"ğŸ” ID {target_id} ì •ë³´ ê°€ì ¸ì˜¤ê¸°...")

    query = '''
    query ($id: Int) {
        Media(id: $id, type: ANIME) {
            id
            idMal
            title { romaji english native }
            type format status description
            season seasonYear episodes duration
            startDate { year month day }
            endDate { year month day }
            coverImage { large color }
            bannerImage
            averageScore meanScore popularity favourites trending
            source countryOfOrigin isAdult isLicensed
            siteUrl
            trailer { id site }
            updatedAt
            genres
            tags {
                id name description category rank
                isGeneralSpoiler isMediaSpoiler isAdult
            }
            studios {
                edges {
                    isMain
                    node {
                        id name isAnimationStudio siteUrl favourites
                    }
                }
            }
            relations {
                edges {
                    relationType
                    node { id type }
                }
            }
            recommendations(perPage: 10) {
                nodes {
                    rating
                    mediaRecommendation { id }
                }
            }
            externalLinks {
                site url type language
            }
            streamingEpisodes {
                title thumbnail url site
            }
            stats {
                scoreDistribution { score amount }
                statusDistribution { status amount }
            }
        }
    }
    '''

    data = client._make_request(query, {'id': target_id})

    if not data or 'Media' not in data:
        print("âŒ API í˜¸ì¶œ ì‹¤íŒ¨")
        crawler.close()
        return False

    anime = data['Media']
    title = anime.get('title', {}).get('romaji', 'Unknown')

    print(f"\nâœ… API ì‘ë‹µ ì„±ê³µ!")
    print(f"   ID: {anime['id']}")
    print(f"   ì œëª©: {title}")
    print(f"   ì˜ì–´: {anime.get('title', {}).get('english', 'N/A')}")
    print(f"   íƒ€ì…: {anime.get('format', 'N/A')}")
    print(f"   ìƒíƒœ: {anime.get('status', 'N/A')}")
    print(f"   ì¸ê¸°ë„: {anime.get('popularity', 0):,}")
    print(f"   í‰ì : {anime.get('averageScore', 'N/A')}")
    print(f"   ì—í”¼ì†Œë“œ: {anime.get('episodes', 'N/A')}")
    print(f"   ì¥ë¥´: {', '.join(anime.get('genres', []))}")

    cover_url = anime.get('coverImage', {}).get('large', 'N/A')
    if len(cover_url) > 60:
        cover_url = cover_url[:60] + "..."
    print(f"   ì»¤ë²„ URL: {cover_url}")

    # DBì— ì €ì¥
    print(f"\nğŸ’¾ DBì— ì €ì¥ ì¤‘...")
    crawler._save_anime(anime)
    crawler.conn.commit()

    # ì €ì¥ í™•ì¸
    cursor.execute("SELECT COUNT(*) FROM anime")
    after_count = cursor.fetchone()[0]

    cursor.execute("""
        SELECT title_romaji, popularity, average_score, format, status, episodes,
               (SELECT COUNT(*) FROM anime_genre WHERE anime_id = ?) as genre_count,
               (SELECT COUNT(*) FROM anime_tag WHERE anime_id = ?) as tag_count,
               (SELECT COUNT(*) FROM anime_studio WHERE anime_id = ?) as studio_count,
               (SELECT COUNT(*) FROM anime_relation WHERE anime_id = ?) as relation_count,
               cover_image_url, cover_image_local
        FROM anime WHERE id = ?
    """, (target_id, target_id, target_id, target_id, target_id))

    result = cursor.fetchone()

    print(f"\nâœ… ì €ì¥ ì™„ë£Œ!")
    print(f"   ì• ë‹ˆë©”ì´ì…˜ ìˆ˜: {before_count} â†’ {after_count} (+{after_count - before_count})")

    if result:
        print(f"\nğŸ“¦ ì €ì¥ëœ ë°ì´í„° ìƒì„¸:")
        print(f"   ì œëª©: {result[0]}")
        print(f"   ì¸ê¸°ë„: {result[1]:,}")
        print(f"   í‰ì : {result[2]}")
        print(f"   í¬ë§·: {result[3]}")
        print(f"   ìƒíƒœ: {result[4]}")
        print(f"   ì—í”¼ì†Œë“œ: {result[5]}")
        print(f"   ì¥ë¥´: {result[6]}ê°œ")
        print(f"   íƒœê·¸: {result[7]}ê°œ")
        print(f"   ìŠ¤íŠœë””ì˜¤: {result[8]}ê°œ")
        print(f"   ê´€ë ¨ ì‘í’ˆ: {result[9]}ê°œ")
        print(f"   ì»¤ë²„ URL: {result[10][:60] if result[10] else 'None'}...")
        print(f"   ë¡œì»¬ ê²½ë¡œ: {result[11]}")

    crawler.close()
    return True

if __name__ == '__main__':
    success = test_specific_anime()
    print(f"\n{'='*60}")
    if success:
        print("âœ… í…ŒìŠ¤íŠ¸ ì„±ê³µ: í¬ë¡¤ë§ì´ ì •ìƒ ë™ì‘í•©ë‹ˆë‹¤!")
        print("   ë‚˜ë¨¸ì§€ ì• ë‹ˆë©”ì´ì…˜ë„ í¬ë¡¤ë§í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
    else:
        print("âš ï¸  í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨")
    print(f"{'='*60}")
