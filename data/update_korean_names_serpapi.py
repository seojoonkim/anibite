#!/usr/bin/env python3
"""
SerpAPIë¥¼ ì‚¬ìš©í•œ ìºë¦­í„° í•œêµ­ì–´ ì´ë¦„ ì—…ë°ì´íŠ¸
- ë´‡ ê°ì§€ ì—†ì´ ì•ˆì •ì ì¸ êµ¬ê¸€ ê²€ìƒ‰
- ë³‘ë ¬ ì²˜ë¦¬ + ì¤‘ê°„ ì €ì¥ ë° ì¬ê°œ ì§€ì›

ì‚¬ìš©ë²•:
    export SERPAPI_KEY="your_api_key"
    python3 data/update_korean_names_serpapi.py
"""
import sys
import os
import re
import json
import asyncio
import argparse
import sqlite3
import time
import signal
import atexit
from datetime import datetime
from pathlib import Path
from urllib.parse import unquote
from concurrent.futures import ThreadPoolExecutor

sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
sys.path.insert(0, os.path.join(os.path.dirname(os.path.dirname(os.path.abspath(__file__))), 'backend'))

from database import db
from config import DATABASE_PATH

try:
    from serpapi import GoogleSearch
except ImportError:
    print("Error: pip install google-search-results")
    sys.exit(1)


# ============================================================
# Configuration
# ============================================================
MAX_WORKERS = 5  # ë™ì‹œ ìš”ì²­ ìˆ˜
REQUEST_DELAY = 0.5  # ìš”ì²­ ê°„ ë”œë ˆì´ (ì´ˆ) - SerpAPIëŠ” ë´‡ ê°ì§€ ì—†ìœ¼ë¯€ë¡œ ì§§ê²Œ
SAVE_EVERY = 10  # ì²˜ë¦¬ Nê°œë§ˆë‹¤ ì €ì¥
MIN_SCORE = 3  # í›„ë³´ ì ìˆ˜ ìµœì†Œ ê¸°ì¤€

# íŒŒì¼ ê²½ë¡œ
PROGRESS_FILE = Path(__file__).parent / "update_korean_serpapi_progress.json"
ERROR_LOG_FILE = Path(__file__).parent / "update_korean_serpapi_errors.log"

# Control flags
stop_requested = False
_global_progress = None

# API Key
SERPAPI_KEY = os.environ.get("SERPAPI_KEY", "")


def log(msg):
    timestamp = datetime.now().strftime("%H:%M:%S")
    print(f"[{timestamp}] {msg}", flush=True)


def log_error(msg):
    timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    with open(ERROR_LOG_FILE, "a", encoding="utf-8") as f:
        f.write(f"[{timestamp}] {msg}\n")


def load_progress():
    if PROGRESS_FILE.exists():
        try:
            with open(PROGRESS_FILE, "r", encoding="utf-8") as f:
                return json.load(f)
        except:
            pass
    return {"processed_ids": [], "updated": {}, "same": [], "not_found": [], "errors": []}


def save_progress(progress):
    try:
        with open(PROGRESS_FILE, "w", encoding="utf-8") as f:
            json.dump(progress, f, ensure_ascii=False, indent=2)
    except Exception as e:
        log_error(f"Failed to save progress: {e}")


def get_all_characters(limit=None, exclude_ids=None):
    """ëª¨ë“  ìºë¦­í„° ì¡°íšŒ"""
    exclude_ids = exclude_ids or []

    query = """
        SELECT DISTINCT
            c.id,
            c.name_full,
            c.name_native,
            c.name_korean,
            c.favourites
        FROM character c
        WHERE c.name_native IS NOT NULL
          AND c.name_full NOT IN ('Narrator', 'Unknown', 'Extra')
          AND c.name_native != ''
          AND LENGTH(c.name_native) >= 2
          AND LENGTH(c.name_full) >= 3
    """

    if exclude_ids:
        placeholders = ",".join("?" * len(exclude_ids))
        query += f" AND c.id NOT IN ({placeholders})"

    query += " ORDER BY c.favourites DESC"

    if limit:
        query += f" LIMIT {limit}"

    if exclude_ids:
        return db.execute_query(query, tuple(exclude_ids))
    return db.execute_query(query)


def is_valid_korean_name(text):
    """ìœ íš¨í•œ í•œêµ­ì–´ ì´ë¦„ì¸ì§€ í™•ì¸"""
    if not text:
        return False
    text = text.strip()
    # í•œê¸€ë§Œ (ê³µë°± í—ˆìš©)
    if not re.match(r'^[ê°€-í£]+(\s[ê°€-í£]+)*$', text):
        return False
    clean = text.replace(' ', '')
    if len(clean) < 2 or len(clean) > 15:
        return False
    # ë¸”ë™ë¦¬ìŠ¤íŠ¸
    blacklist = ['ì´ë¦„', 'ëª©ì°¨', 'ê°œìš”', 'ë“±ì¥ì¸ë¬¼', 'ì£¼ì¸ê³µ', 'ì„¤ëª…', 'íŠ¹ì§•', 'ë¶„ë¥˜',
                 'ì„±ìš°', 'ë°°ìš°', 'ì¶œìƒ', 'ì¶œì‹ ', 'ê¸°íƒ€', 'ê´€ê³„', 'ê°ì£¼', 'ëª©ë¡',
                 'ê²€ìƒ‰', 'ê²°ê³¼', 'ë‚˜ë¬´ìœ„í‚¤', 'ìœ„í‚¤ë°±ê³¼', 'ë”ë³´ê¸°', 'ê´€ë ¨', 'ë¬¸ì„œ',
                 'ì• ë‹ˆë©”ì´ì…˜', 'ë§Œí™”', 'ê²Œì„', 'ì†Œì„¤', 'ì‘í’ˆ', 'ì‹œë¦¬ì¦ˆ', 'ìºë¦­í„°',
                 'ê³µì‹', 'ì •ë³´', 'í”„ë¡œí•„', 'ì†Œê°œ', 'í•œêµ­ì–´', 'ì¼ë³¸ì–´', 'ì˜ì–´',
                 'ë²ˆì—­', 'ë°œìŒ', 'í‘œê¸°', 'ì›ë¬¸', 'ìŠ¤í¬ì¼ëŸ¬', 'ì¤„ê±°ë¦¬']
    if text in blacklist:
        return False
    return True


def extract_korean_name_from_results(results, name_full, name_native=None):
    """SerpAPI ê²€ìƒ‰ ê²°ê³¼ì—ì„œ í•œêµ­ì–´ ì´ë¦„ ì¶”ì¶œ"""
    candidates = {}
    name_full_lower = name_full.lower()

    def add_candidate(candidate, score, reason):
        if not is_valid_korean_name(candidate):
            return
        entry = candidates.setdefault(candidate, {"score": 0, "count": 0, "reason": reason})
        entry["score"] += score
        entry["count"] += 1
        if score >= entry.get("best_score", 0):
            entry["reason"] = reason
            entry["best_score"] = score

    # organic_results ì²˜ë¦¬
    organic = results.get("organic_results", [])
    for result in organic:
        title = result.get("title", "")
        snippet = result.get("snippet", "")
        link = result.get("link", "")

        # íŒ¨í„´ 1: ë‚˜ë¬´ìœ„í‚¤ ì œëª©ì—ì„œ ì¶”ì¶œ
        if "namu.wiki" in link:
            match = re.search(r'^([ê°€-í£]{2,12}(?:\s[ê°€-í£]{1,12})?)', title)
            if match:
                add_candidate(match.group(1).strip(), 5, "namu_title")

            # URLì—ì„œ ì¶”ì¶œ
            url_match = re.search(r'namu\.wiki/w/([ê°€-í£%]+)', link)
            if url_match:
                try:
                    name = unquote(url_match.group(1))
                    name = re.sub(r'[\(ï¼ˆ].*?[\)ï¼‰]$', '', name).strip()
                    add_candidate(name, 5, "namu_url")
                except:
                    pass

        # íŒ¨í„´ 2: ìœ„í‚¤í”¼ë””ì•„
        if "wikipedia" in link:
            match = re.search(r'^([ê°€-í£]{2,12}(?:\s[ê°€-í£]{1,12})?)', title)
            if match:
                add_candidate(match.group(1).strip(), 4, "wiki_title")

        # íŒ¨í„´ 3: ì œëª©ì—ì„œ "í•œêµ­ì–´ì´ë¦„(ì˜ì–´ì´ë¦„)" íŒ¨í„´
        match = re.search(r'^([ê°€-í£]{2,12}(?:\s[ê°€-í£]{1,12})?)\s*[\(ï¼ˆ]', title)
        if match and name_full_lower in title.lower():
            add_candidate(match.group(1).strip(), 4, "paren_with_english")

        # íŒ¨í„´ 4: snippetì—ì„œ í•œêµ­ì–´ ì´ë¦„ ì¶”ì¶œ
        for text in [title, snippet]:
            if name_full_lower in text.lower():
                for name in re.findall(r'[ê°€-í£]{2,12}(?:\s[ê°€-í£]{1,12})?', text):
                    add_candidate(name, 2, "same_line")

            if name_native and name_native in text:
                for name in re.findall(r'[ê°€-í£]{2,12}(?:\s[ê°€-í£]{1,12})?', text):
                    add_candidate(name, 2, "native_line")

    # knowledge_graph ì²˜ë¦¬ (ìˆëŠ” ê²½ìš°)
    kg = results.get("knowledge_graph", {})
    if kg:
        kg_title = kg.get("title", "")
        match = re.search(r'^([ê°€-í£]{2,12}(?:\s[ê°€-í£]{1,12})?)', kg_title)
        if match:
            add_candidate(match.group(1).strip(), 6, "knowledge_graph")

    if not candidates:
        return None, None

    best_name, meta = max(
        candidates.items(),
        key=lambda item: (item[1]["score"], item[1]["count"], -len(item[0]))
    )
    if meta["score"] < MIN_SCORE:
        return None, None
    return best_name, meta.get("reason")


def search_google(name_full, name_native, api_key):
    """SerpAPIë¡œ êµ¬ê¸€ ê²€ìƒ‰"""
    query = f'"{name_full}" ì´ë¦„'

    params = {
        "q": query,
        "hl": "ko",
        "gl": "kr",
        "api_key": api_key,
        "num": 10,
    }

    try:
        search = GoogleSearch(params)
        results = search.get_dict()

        if "error" in results:
            log_error(f"SerpAPI error for {name_full}: {results['error']}")
            return None, None

        korean_name, reason = extract_korean_name_from_results(results, name_full, name_native)

        # ì²« ë²ˆì§¸ ê²€ìƒ‰ì—ì„œ ëª» ì°¾ìœ¼ë©´ ì¼ë³¸ì–´ ì´ë¦„ìœ¼ë¡œ ì¬ê²€ìƒ‰
        if not korean_name and name_native:
            query2 = f'"{name_full}" "{name_native}" ì´ë¦„'
            params["q"] = query2
            search2 = GoogleSearch(params)
            results2 = search2.get_dict()
            korean_name, reason = extract_korean_name_from_results(results2, name_full, name_native)

        return korean_name, reason

    except Exception as e:
        log_error(f"Search error for {name_full}: {e}")
        return None, None


def process_character(character, api_key):
    """ë‹¨ì¼ ìºë¦­í„° ì²˜ë¦¬"""
    char_id = character['id']
    name_full = character['name_full']
    name_native = character['name_native']
    current_korean = character['name_korean']

    found_korean, reason = search_google(name_full, name_native, api_key)

    return {
        "id": char_id,
        "name_full": name_full,
        "name_native": name_native,
        "current_korean": current_korean,
        "found_korean": found_korean,
        "reason": reason
    }


def emergency_save():
    """ê¸´ê¸‰ ì €ì¥"""
    global _global_progress
    if _global_progress:
        try:
            save_progress(_global_progress)
            log("ğŸ’¾ ê¸´ê¸‰ ì €ì¥ ì™„ë£Œ")
        except Exception as e:
            log_error(f"Emergency save failed: {e}")


def handle_signal(signum, frame):
    global stop_requested
    stop_requested = True
    log(f"âš  ì¢…ë£Œ ì‹ í˜¸ ìˆ˜ì‹ . ì €ì¥ í›„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
    emergency_save()
    sys.exit(0)


atexit.register(emergency_save)


def main():
    global _global_progress, SERPAPI_KEY, MAX_WORKERS, REQUEST_DELAY, MIN_SCORE

    parser = argparse.ArgumentParser(description="SerpAPIë¡œ ìºë¦­í„° í•œêµ­ì–´ ì´ë¦„ ê²€ì¦/ì—…ë°ì´íŠ¸")
    parser.add_argument("--workers", type=int, default=MAX_WORKERS)
    parser.add_argument("--delay", type=float, default=REQUEST_DELAY)
    parser.add_argument("--limit", type=int, default=None)
    parser.add_argument("--min-score", type=int, default=MIN_SCORE)
    parser.add_argument("--api-key", type=str, default=SERPAPI_KEY)
    args = parser.parse_args()

    MAX_WORKERS = max(1, args.workers)
    REQUEST_DELAY = max(0.1, args.delay)
    MIN_SCORE = max(1, args.min_score)
    SERPAPI_KEY = args.api_key or os.environ.get("SERPAPI_KEY", "")

    if not SERPAPI_KEY:
        print("Error: SERPAPI_KEY í™˜ê²½ë³€ìˆ˜ë¥¼ ì„¤ì •í•˜ê±°ë‚˜ --api-key ì˜µì…˜ì„ ì‚¬ìš©í•˜ì„¸ìš”")
        print("  export SERPAPI_KEY='your_api_key'")
        print("  ë˜ëŠ”")
        print("  python3 update_korean_names_serpapi.py --api-key 'your_api_key'")
        sys.exit(1)

    signal.signal(signal.SIGINT, handle_signal)
    signal.signal(signal.SIGTERM, handle_signal)

    log("=" * 60)
    log("ğŸ” SerpAPIë¡œ ìºë¦­í„° í•œêµ­ì–´ ì´ë¦„ ì—…ë°ì´íŠ¸")
    log(f"   Worker: {MAX_WORKERS}ê°œ")
    log(f"   ë”œë ˆì´: {REQUEST_DELAY}ì´ˆ")
    log(f"   ìµœì†Œ ì ìˆ˜: {MIN_SCORE}")
    log("=" * 60)

    progress = load_progress()
    _global_progress = progress
    processed_ids = progress.get("processed_ids", [])

    if processed_ids:
        log(f"\nğŸ“‚ ì´ì „ ì§„í–‰ ìƒí™©:")
        log(f"   ì²˜ë¦¬ë¨: {len(processed_ids)}ê°œ")
        log(f"   ì—…ë°ì´íŠ¸: {len(progress.get('updated', {}))}ê°œ")
        log(f"   ë™ì¼: {len(progress.get('same', []))}ê°œ")
        log(f"   ëª»ì°¾ìŒ: {len(progress.get('not_found', []))}ê°œ")

    log("\nğŸ“‹ ìºë¦­í„° ì¡°íšŒ ì¤‘...")
    characters = get_all_characters(limit=args.limit, exclude_ids=processed_ids)
    total_count = len(characters)

    log(f"   ì´ {total_count}ê°œ ìºë¦­í„°")

    if total_count == 0:
        log("âœ… ì²˜ë¦¬í•  ìºë¦­í„°ê°€ ì—†ìŠµë‹ˆë‹¤!")
        return

    log(f"\nğŸ”„ ê²€ìƒ‰ ì‹œì‘...")
    start_time = datetime.now()

    # DB ì—°ê²°
    conn = sqlite3.connect(str(DATABASE_PATH), timeout=60.0)
    conn.execute("PRAGMA journal_mode=WAL")
    cursor = conn.cursor()

    processed_ids_set = set(processed_ids)
    same_ids = set(progress.get("same", []))
    not_found_ids = set(progress.get("not_found", []))
    updated_map = progress.get("updated", {})
    errors = progress.get("errors", [])

    processed_count = 0
    success_count = 0
    updated_count = 0

    try:
        with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:
            for i, character in enumerate(characters):
                if stop_requested:
                    break

                result = process_character(character, SERPAPI_KEY)

                processed_count += 1
                char_id = result["id"]
                name_full = result["name_full"]
                current_korean = result["current_korean"]
                found_korean = result["found_korean"]
                reason = result.get("reason")

                if found_korean:
                    success_count += 1
                    if current_korean != found_korean:
                        try:
                            cursor.execute(
                                "UPDATE character SET name_korean = ? WHERE id = ?",
                                (found_korean, char_id)
                            )
                            updated_count += 1
                            updated_map[str(char_id)] = {
                                "name": name_full,
                                "old": current_korean,
                                "new": found_korean,
                                "reason": reason
                            }
                            log(f"âœ“ [{processed_count}/{total_count}] {name_full}: {current_korean or 'ì—†ìŒ'} â†’ {found_korean}")
                        except Exception as e:
                            errors.append({"id": char_id, "name": name_full, "error": str(e)})
                            log_error(f"DB update failed for {char_id} {name_full}: {e}")
                    else:
                        same_ids.add(char_id)
                else:
                    not_found_ids.add(char_id)

                processed_ids_set.add(char_id)

                # ì£¼ê¸°ì  ì €ì¥
                if processed_count % SAVE_EVERY == 0:
                    conn.commit()
                    progress["processed_ids"] = list(processed_ids_set)
                    progress["same"] = list(same_ids)
                    progress["not_found"] = list(not_found_ids)
                    progress["updated"] = updated_map
                    progress["errors"] = errors
                    save_progress(progress)

                    rate = success_count / processed_count * 100 if processed_count > 0 else 0
                    log(f"\n{'='*50}")
                    log(f"ğŸ“Š ì§„í–‰: {processed_count}/{total_count} ({processed_count/total_count*100:.1f}%)")
                    log(f"   ì°¾ìŒ: {success_count}ê°œ ({rate:.1f}%)")
                    log(f"   ì—…ë°ì´íŠ¸: {updated_count}ê°œ")
                    log(f"{'='*50}\n")

                # ë”œë ˆì´
                time.sleep(REQUEST_DELAY)

        conn.commit()

    finally:
        conn.close()

    # ìµœì¢… ì €ì¥
    progress["processed_ids"] = list(processed_ids_set)
    progress["same"] = list(same_ids)
    progress["not_found"] = list(not_found_ids)
    progress["updated"] = updated_map
    progress["errors"] = errors
    save_progress(progress)

    elapsed = (datetime.now() - start_time).total_seconds()

    log(f"\n{'='*60}")
    log("ğŸ‰ ì™„ë£Œ!")
    log(f"  ì²˜ë¦¬: {processed_count}ê°œ")
    log(f"  ì°¾ìŒ: {success_count}ê°œ ({success_count/max(processed_count,1)*100:.1f}%)")
    log(f"  ì—…ë°ì´íŠ¸: {updated_count}ê°œ")
    log(f"  ì‹œê°„: {elapsed/60:.1f}ë¶„")
    log(f"  ì†ë„: {processed_count/max(elapsed,1)*60:.1f}ê°œ/ë¶„")
    log(f"{'='*60}\n")


if __name__ == "__main__":
    main()
